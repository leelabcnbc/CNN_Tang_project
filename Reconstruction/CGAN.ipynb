{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "binary_cross_entropy = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generator_loss(label, fake_output):\n",
    "    gen_loss = binary_cross_entropy(label, fake_output)\n",
    "    #print(gen_loss)\n",
    "    return gen_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def discriminator_loss(label, output):\n",
    "    disc_loss = binary_cross_entropy(label, output)\n",
    "    #print(total_loss)\n",
    "    return disc_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])])\n",
    "train_dataset = datasets.ImageFolder(root='rps', transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "\n",
    "        self.label_conditioned_generator =\n",
    "        nn.Sequential(nn.Embedding(n_classes, embedding_dim),\n",
    "                      nn.Linear(embedding_dim, 16))\n",
    "\n",
    "\n",
    "        self.latent =\n",
    "        nn.Sequential(nn.Linear(latent_dim, 4*4*512),\n",
    "                      nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "\n",
    "        self.model =\n",
    "        nn.Sequential(nn.ConvTranspose2d(513, 64*8, 4, 2, 1, bias=False),\n",
    "                      nn.BatchNorm2d(64*8, momentum=0.1,  eps=0.8),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.ConvTranspose2d(64*8, 64*4, 4, 2, 1,bias=False),\n",
    "                      nn.BatchNorm2d(64*4, momentum=0.1,  eps=0.8),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.ConvTranspose2d(64*4, 64*2, 4, 2, 1,bias=False),\n",
    "                      nn.BatchNorm2d(64*2, momentum=0.1,  eps=0.8),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.ConvTranspose2d(64*2, 64*1, 4, 2, 1,bias=False),\n",
    "                      nn.BatchNorm2d(64*1, momentum=0.1,  eps=0.8),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.ConvTranspose2d(64*1, 3, 4, 2, 1, bias=False),\n",
    "                      nn.Tanh())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        noise_vector, label = inputs\n",
    "        label_output = self.label_conditioned_generator(label)\n",
    "        label_output = label_output.view(-1, 1, 4, 4)\n",
    "        latent_output = self.latent(noise_vector)\n",
    "        latent_output = latent_output.view(-1, 512,4,4)\n",
    "        concat = torch.cat((latent_output, label_output), dim=1)\n",
    "        image = self.model(concat)\n",
    "        #print(image.size())\n",
    "        return image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "\n",
    "        self.label_condition_disc =\n",
    "        nn.Sequential(nn.Embedding(n_classes, embedding_dim),\n",
    "                      nn.Linear(embedding_dim, 3*128*128))\n",
    "\n",
    "        self.model =\n",
    "        nn.Sequential(nn.Conv2d(6, 64, 4, 2, 1, bias=False),\n",
    "                      nn.LeakyReLU(0.2, inplace=True),\n",
    "                      nn.Conv2d(64, 64*2, 4, 3, 2, bias=False),\n",
    "                      nn.BatchNorm2d(64*2, momentum=0.1,  eps=0.8),\n",
    "                      nn.LeakyReLU(0.2, inplace=True),\n",
    "                      nn.Conv2d(64*2, 64*4, 4, 3,2, bias=False),\n",
    "                      nn.BatchNorm2d(64*4, momentum=0.1,  eps=0.8),\n",
    "                      nn.LeakyReLU(0.2, inplace=True),\n",
    "                      nn.Conv2d(64*4, 64*8, 4, 3, 2, bias=False),\n",
    "                      nn.BatchNorm2d(64*8, momentum=0.1,  eps=0.8),\n",
    "                      nn.LeakyReLU(0.2, inplace=True),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(4608, 1),\n",
    "                      nn.Sigmoid()\n",
    "                      )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        img, label = inputs\n",
    "        label_output = self.label_condition_disc(label)\n",
    "        label_output = label_output.view(-1, 3, 128, 128)\n",
    "        concat = torch.cat((img, label_output), dim=1)\n",
    "        #print(concat.size())\n",
    "        output = self.model(concat)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "latent_dim = 128\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "D_optimizer = torch.optim.Adam(lr=1e-3,params=discriminator.parameters())\n",
    "G_optimizer = torch.optim.Adam(lr=1e-3,params=generator.parameters())\n",
    "device = ('cuda')\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    D_loss_list, G_loss_list = [], []\n",
    "\n",
    "    for index, (real_images, labels) in enumerate(train_loader):\n",
    "        D_optimizer.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.unsqueeze(1).long()\n",
    "\n",
    "\n",
    "        real_target = Variable(torch.ones(real_images.size(0), 1).to(device))\n",
    "        fake_target = Variable(torch.zeros(real_images.size(0), 1).to(device))\n",
    "\n",
    "        D_real_loss = discriminator_loss(discriminator((real_images, labels)), real_target)\n",
    "        # print(discriminator(real_images))\n",
    "        #D_real_loss.backward()\n",
    "\n",
    "        noise_vector = torch.randn(real_images.size(0), latent_dim, device=device)\n",
    "        noise_vector = noise_vector.to(device)\n",
    "\n",
    "\n",
    "        generated_image = generator((noise_vector, labels))\n",
    "        output = discriminator((generated_image.detach(), labels))\n",
    "        D_fake_loss = discriminator_loss(output,  fake_target)\n",
    "\n",
    "\n",
    "        # train with fake\n",
    "        #D_fake_loss.backward()\n",
    "\n",
    "        D_total_loss = (D_real_loss + D_fake_loss) / 2\n",
    "        D_loss_list.append(D_total_loss)\n",
    "\n",
    "        D_total_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # Train generator with real labels\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss = generator_loss(discriminator((generated_image, labels)), real_target)\n",
    "        G_loss_list.append(G_loss)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
